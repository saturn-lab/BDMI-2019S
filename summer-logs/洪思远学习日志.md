﻿﻿﻿﻿**2019/07/17**1. 学习数据库发展历程和必要性；2. 学习单数据库查询语法，如SFW（*代表所有数据），AND，LIMIT等；注意项：3. 学习多数据库查询语法，如JOINS，PRIMARY KEY 和 FOREIGN KEY。4. 底层排序。﻿﻿﻿﻿**2019/07/18****1. 计算机系统**- 计算机架构：冯 诺依曼结构- 计算机存储等级（4级）：寄存器/缓存、主存、硬盘- 处理器：指令集（x86和ARM）、微架构（使ISA能够在处理器上执行）**2. Bitmap Indexing**- 索引结构：Tree、Hash、Bitmap- bitwise operation- 优点：  - 压缩性好  - 运算速度快- FastBit：WAH和PLWAH（节省空间）**3. 深度学习**- Stanford CS231 CNN，Numpy- softmax函数将数值转为概率向量- 神经网络训练的本质是计算相应的内部权重，使得训练数据（样本）输入到网络后，网络的实际输出与预期输出（即标签）之间的差异最小。- 损失函数的具体方式： - 回归任务：均方误差公式  - 分布任务：交叉熵公式- 反向传播算法（backprop）：反向逐层计算损失函数对权重的梯度（偏导）。- 梯度下降法（Gradient Descend）：找到一个函数的局部极小值，向当前点对应梯度的反方向，按照规定步长距离点，进行迭代搜索。- 随机梯度下降法（Stochastic Gradient Descend，SGD）：最常用的权重调节方法，通过权重的调整，最小化损失函数。其核心是随机样本。﻿﻿﻿﻿**2019/07/19****1. TensorFlow**- Dense 多层Dense构成MLP，用于解决分类问题。 例：1-neural-network-mnist- CNN  - 特点：局部区域的权重W共享 。  - 超参数：卷积核大小和个数。  - Pooling层：采样缩小模型大小（一个2*2的核，strides=2的pooling层，等于减少75%的输出），但不会改变tensor的深度。 - Dropout层：较少CNN过拟合问题。 - 论文：_ImageNet classification with deep convolutional neural networks._- RNN 在时间维度上，每一个时间步处理时，采用共享的权重。用于序列建模预测问题。- 双向RNN 语音识别和手写识别。**2. 语音识别（ASR）**  - 经典的ASR过程：语音信号经过傅里叶变换（STFFT），把连续语言分解成一组短期向量，然后应用各种变换把这个向量序列变换为一个因素序列，然后变换到字母序列，然后到词汇序列。 - 基于深度学习的语音识别：深度学习模型需要训练数据和评价驱动的方法来进行参数优化。  - CTC折叠