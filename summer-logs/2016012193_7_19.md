# 第五天学习日志

​	今天复习了一下深度学习框架和tensorflow，然后介绍了两个神经网络CNN和RNN。

---

* 深度学习框架

  深度学习框架是一种编程语言（可求导编程语言），编程语言+编译器+解释器，目前以python作为载体。tensorflow就是其中的一个例子。

  **可求导**是很重要的特点，这让它可以通过求导法则反向求出所有函数的导数，进而确定权重，

  eg.

  ReLU作为激活函数，w权重，x输入值，b权重，F(wx+b)和预期比较得到偏差，我们希望偏差尽可能小，因此希望偏差的导数为0，进而可以求出权重们。

* CNN（卷积神经网络）

  1.神经元Neuron。由F(wx+b)和预期比较得到偏差，单个操作；

  2.Dense网络。神经元不止一个，它们处理输入值得到各个待输出值，再经过softmax()函数（其他函数应该也行吧）得到最后的输出值，但是缺点就是数据量增大时计算量大增；

  3.CNN卷积神经网络。算是对2.的一个优化，它利用卷积核，让卷积核映射到的**同一个局部区域可以共用权重**，从而减少计算量，用到的卷积核有2d和3d等。（其实很奇怪为什么可以这样干欸，是类似于图片像素降低那样的做法吗，认为相近区域的差异不大？没道理啊><）

* RNN（循环神经网络）

  CNN是前馈网络，处理的数据没有先后关系，而反馈网路的RNN可以处理有先后关系的数据，比如说音频信息。（其实就是在CNN的基础上，F()的输入值多了上一步得到的中间值作为权重罢了，所以得到的是一堆并排的CNN）。

  RNN的一些实用的变种：

  1.LSTM。将三个门电路放在input/output/中间计算步上，防止了传统RNN梯度消失或者梯度爆炸的情况；

  2.CTC。

