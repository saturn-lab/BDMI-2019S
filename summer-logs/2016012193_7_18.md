# 第四天学习日志

​		今天首先是讲了一下计算机组成原理的补充，然后讲了一下Bitmap索引，之后转到机器学习和深度学习，再用 tensorflow 运行了一些例子。又是学过一次的东西，但前两者还好说，后面关于激活函数的东西还是一脸懵逼。。

---

* 计算机系统

  找不到课件了，就写下自己记得又觉得好玩的东西吧。

  **1.程序的编译。**

  在C语言里程序需要预处理、编译、汇编、链接之后才可以产生可执行的二进制文件，（当然不同的语言可能会省略一部分），汇编语言超级有意思！

  **2.计算机的存储层级。**

  从磁盘，到主存，再到各层级的高速缓存，最后到寄存器，越来越贵，也越来越快。这种成本和效率的权衡所造就的多级缓存的设计真的太精彩了！当然这种多级缓存利用了多数程序会具有空间或者时间的局部性，这也提醒我们在程序编写时也需要考虑到这一特点的体现。

  ​	感觉了解一下计算机系统的架构过程还是很有必要的，写代码的时候有时候还会考虑一下这方面的优化，强推计组课，老师超级可爱！

* Bitmap索引

  对于某一个索引，我们可以把键值用**位串**来表示（eg.一个一百以内的正整数的键值，我们就可以用000...1...000，其中1在第几位表示该值的大小来表示）。

  优点：

  1.位处理比较快，而且空间复杂度其实也不会大多少；

  2.和计算机系统结构相性更好；

  3.容易处理多维问题（树索引对于多维问题处理不好，比如进行多条件的query时会费时间，但没想明白位图索引要怎么处理呢？好像在这个例子里也不行nia，是例子不恰当还是我理解错了，以后补充...）。

  当然啦，怎么把键值表示成**位串**也是一件技术活，简单的可以用1出现在第几位表示整形，复杂的可以把一些简单的串简写或者合并，还是可以有点东西深究出来的，（mark一下）。

* 机器学习

  预测：通过数据集，预测新的数值；

  分类：通过数据集，对新数据来进行集合分类；

  数据集很关键。

* 深度学习

  对神经元的建模：输入值->输出值，我们用一个函数F(w,x)表示，其中F是一个非线性函数，称为激活函数，w是权重，x是输入值。

  激活函数的挑选：sigmod()，tanh()，ReLU()

  然后是连接主义引导的网络（神经元连接，由输入层开始经过若干的隐藏层才可以到达最后的输出层）：前馈/反馈/记忆

* Tensorflow

  （ 噗(/≧▽≦)/，其实并不知道他是啥）TensorFlow是一个采用数据流图（data flow graphs），用于数值计算的开源软件库，（既然是库，那里面的东西就，加油看吧）。

* 出现的问题

  1.计组的知识再去复习一下子；

  2.bitmap索引是怎么处理多维问题的呀；

  3.pip直接装tensorflow是有版本限制的，至少3.7不可以，3.6可以，mark一下。