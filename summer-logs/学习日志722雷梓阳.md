学习日志722雷梓阳

计算机视觉Visual Object Detection

计算机视觉的任务

计算机视觉的识别指标

视觉对象的检测方法

图像语义的分割方法

计算机视觉就是用计算机代替人眼做测量和判断

物体识别采用的策略一般是：分类 定位 检测 分割

精确率precision（预测了100张猫，有九十张猫），召回率recall：表示的是样本中的正例有多少被预测正确了，准确率accuracy（测试集里有100张猫，预测出了90张猫）



平均精确率均值mAP，PR曲线的覆盖率（面积覆盖率AUC）

*mAP的计算方法（引自CSDN）（绿色行应改为3/6）

![img](https://upload-images.jianshu.io/upload_images/6605643-d56b4ea5e7e5178b.png?imageMogr2/auto-orient/)



最佳工作状态F1 = P与R的调和平均数



IOU重叠联合比

正确的IOU>0.5

定位错误0.1<IOU<0.5

相似性错误，识别错误IOU>0.1

背景误认IOU<0.1



R-CNN：regions with CNN features 

·输入图像，提取提炼区域

·计算CNN特征

·区域分类

对象识别和定位，可以看成两个任务：找到图片中某个存在对象的区域，然后识别出该区域中具体是哪个对象。
对象识别这件事（一张图片仅包含一个对象，且基本占据图片的整个范围），最近几年基于CNN卷积神经网络的各种方法已经能达到不错的效果了。所以主要需要解决的问题是，对象在哪里。

最简单的想法，就是遍历图片中所有可能的位置，地毯式搜索不同大小，不同宽高比，不同位置的每个区域，逐一检测其中是否存在某个对象，挑选其中概率最大的结果作为输出。显然这种方法效率太低。

RCNN开创性的提出了候选区(Region Proposals)的方法，先从图片中搜索出一些可能存在对象的候选区（Selective Search），大概2000个左右，然后对每个候选区进行对象识别。大幅提升了对象识别和定位的效率。





YOLO（You Only Look Once）算法将对目标检测任务由分类问题化简为回归问题，创造性的将候选区和对象识别这两个阶段合二为一，看一眼图片（不用看两眼哦）就能知道有哪些对象以及它们的位置。

*将图片划分为 7x7=49 个网格（grid），每个网格允许预测出2个边框（bounding box，包含某个对象的矩形框），总共 49x2=98 个bounding box。可以理解为98个候选区，它们很粗略的覆盖了图片的整个区域。*

将整张图像输入到神经网络中，对图像进行预处理，分割为SXS个网格。每个网格除了回归自己的位置之外，还要预测B个bounding box，同时还要计算一个confidence 

![img](https://img-blog.csdn.net/20180606164218784)

其中如果有 object 落在一个 grid cell 里，第一项取 1，否则取 0。 第二项是预测的 bounding box 和实际的 groundtruth 之间的 IoU 值。

每个 bounding box 要预测 (x, y, w, h) 和 confidence 共5个值，每个网格还要预测一个类别信息，记为 C 类。则 SxS个 网格，每个网格要预测 B 个 bounding box 还要预测 C 个 categories。输出就是 S x S x (5*B+C) 的一个 tensor。

*YOLO深度理解https://segmentfault.com/a/1190000016692873

