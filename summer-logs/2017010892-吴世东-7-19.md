深度学习框架

编程语言，解释器，编译器

底层是网络层和推断层



## CNN&RNN

Dense网络：多层Dense构成MLP，用于解决分类问题



CNN组成

convolutional layers 卷积层 

• pooling layers 采样层 

• normalization layers 正则层(dropout) 

• MLP 分类器

特点：局部区域的权重W共⽤ （weight sharing）（空间维度） 

• 每⼀个卷积层后通常紧跟着⼀个下采 样层subsample

定义输⼊的⻓度(W), 卷积核的⼤⼩(F), 核移 动的步⻓stride(S), zero padding(P)

输出的⻓度L = (W-F+2P)/S+1

并⾏化: 做⼀个和输出⼀样⼤⼩的Layer,  Layer⾥⾯所有的神经元参数都⼀样

Pooling层 

意义: 采样,缩⼩模型⼤⼩ 

• 排列结构: Layer的结构是3d 

• 超参数: pooling_type, window_shape,  padding, strides

pooling层并不会改变tensor的深度

Dropout层 

意义: 减少CNN过拟合问题 

• 超参数: keep_prob 丢弃率 

• 对于所有的输⼊, 有keep_prob概率保 留并乘以1/keep_prob, 以保证前后总 和⼤致相等, 否则输出0

RNN & LSTM

RNN

循环⽹络结构 

​	y是训练⽬标 

​	L是损失函数 

​	o是⽹络输出 

​	h是状态（隐藏单元） 

​	x是⽹络输⼊

权重共享

​	循环神经⽹络在不同的 

​	时间步上采⽤相同的 

U、V、W参数 

​	 输⼊到隐藏的连接由权 重矩阵U 参数化 

​	 隐藏到输出的连接由权 重矩阵V 参数化 

​	 隐藏到隐藏的循环连接 由权重矩阵W 参数化

语音识别

