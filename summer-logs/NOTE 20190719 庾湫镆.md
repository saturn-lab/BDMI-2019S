# NOTE 2019/07/19

## 深度学习框架

每个软件框架背后都有一个大科技企业

云的发展让应用与软硬件分离，软硬件融合发展成为趋势，核心是省电



TensorFlow

前向求损失函数

反向求导得梯度



核心仍然是矩阵运算，矩阵运算加速器



推断库：将模型放在可以在小型设备上的库



# CNN&RNN

#### 卷积网络发展

Lenet->AlexNet 深度显著提升，训练样本变大

AlexNet之后，新的网络结构不断提出： 

• AlexNet—>NiN—>VGG—>GoogleNet—>ResNet —>DenseNet 

• 网络规模与深度都在增加，准确率提升 

• NiN 引入1*1卷积层（Bottlenecklayer）和全局池化； 

• VGG将7*7卷积核替换成3个3*3卷积核，起到了降参数的作用； 

• GoogLeNet引入了Inception模块； 

• ResNet引入了残差思想，增加了Skip Connection； 

• DenseNet的DenseBlock中将当前层的输出特征，与之后所有的层做直连。

### layer

单个神经元：输入1d，参数1d，输出0dememsion



### Dense（MLP）

超参数



notebook: 1_neural_network_mnist

input : picture 28\*28= 784\*1



问题：全连接，对于图片，参数数目巨大，导致计算量巨大



### CNN 组成

convolutional layers 卷积层

pooling layers 采样层

normalization layers 正则层

MLP分类器



##### 卷积核：

图片：5\*5, 卷积核： 3\*3, 用卷积核依次扫描图片，输出tensor为7\*7

三维同理



只需要定下来卷积核的参数，就可以得到网络。

卷积核的大小与个数



卷积的优势，显著减少参数个数



pooling: 将2a\* 2a 的图片缩成a*a，

max pooling，取4个像素中的最大者



### RNN

语音、视频识别，具有时间上的相关性，计算在时间上展开。



训练方法：通过时间的反向截断



#### LSTM

增加cell对输入输出遗忘的门电路控制。



## 语音识别

时频谱图：一段小时间内，对信号作傅里叶变换，形成时间-频率-强度的三维图像

谷歌CLDNN

​	输入信号进行卷积运算，然后压平降低维度，结合了卷积网络LSTM和DNN



困难：1 同音词

2 口音语气强调

3 噪声干扰



CTC

可能识别出Heelllo合并为Hello





作业：on github

audioPlot

audionet

android audiorecg

录音

[http://wiki.icenter.tsinghua.edu.cn/icenterwiki/index.php/%E8%93%9D%E7%89%99%E8%AE%BE%E5%A4%87-%E8%AF%AD%E9%9F%B3%E6%8C%87%E4%BB%A4](http://wiki.icenter.tsinghua.edu.cn/icenterwiki/index.php/蓝牙设备-语音指令)

重命名：bb.m4a

